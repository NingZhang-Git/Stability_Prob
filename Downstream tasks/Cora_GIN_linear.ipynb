{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0PAH0IIgtaFE"
      },
      "outputs": [],
      "source": [
        "# Download the corresponding PyTorch Geometric module\n",
        "%%capture\n",
        "\"\"\"\n",
        "Assign to TORCH with what you get from the cell above, E.g., export TORCH=1.13.1+cu113\n",
        "\"\"\"\n",
        "%env TORCH=2.1.0+cu118\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEuOswTPtuWe",
        "outputId": "68a88030-5f31-40f8-93ba-40dee65ddfee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the Cora dataset\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "# Check if CUDA is available and use it\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the data to the device (GPU if available)\n",
        "data = data.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl5Culw_twBY",
        "outputId": "88652674-d407-4f7f-d83a-d69067f2d46f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GINConv, global_mean_pool, global_max_pool\n",
        "import random\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "class GINMLP(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(GINMLP, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(input_dim, output_dim)\n",
        "        # self.relu = torch.nn.ReLU()\n",
        "        # self.linear2 = torch.nn.Linear(output_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.linear2(x)\n",
        "        return x\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"Resets the parameters of the linear layers within the MLP.\"\"\"\n",
        "        self.linear1.reset_parameters()\n",
        "        # self.linear2.reset_parameters()\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GIN, self).__init__()\n",
        "        # Replace GCNConv with GINConv, using the GINMLP\n",
        "        # self.conv1 = GINConv(GINMLP(input_dim, hidden_dim))\n",
        "        # self.conv2 = GINConv(GINMLP(hidden_dim, hidden_dim))\n",
        "        self.conv1 = GINConv(GINMLP(input_dim, hidden_dim))\n",
        "        self.conv2 = GINConv(GINMLP(hidden_dim, hidden_dim))\n",
        "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x) # Apply activation after GINConv\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x) # Apply activation after GINConv\n",
        "        x = self.lin(x)\n",
        "        return x\n",
        "\n",
        "    def get_ebd(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x) # Apply activation after GINConv\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x) # Apply activation after GINConv\n",
        "        return x"
      ],
      "metadata": {
        "id": "HYMcf6Rxt0wf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "def train(model, data, optimizer, criterion, epochs=200):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        # Get the node features (data.x) and edge indices (data.edge_index)\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
        "        acc = correct / data.test_mask.sum()\n",
        "        return acc.item()\n",
        "\n",
        "def reset_weights(m):\n",
        "    if isinstance(m, (torch.nn.Linear)):\n",
        "        m.reset_parameters()"
      ],
      "metadata": {
        "id": "6sUplL13t4c4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model hyperparameters\n",
        "in_channels = dataset.num_node_features  # 1433 (Cora input feature size)\n",
        "hidden_channels = 64\n",
        "out_channels = dataset.num_classes  # 7 (Cora has 7 classes)\n",
        "# Initialize the model\n",
        "model = GIN(in_channels, hidden_channels, out_channels).to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n"
      ],
      "metadata": {
        "id": "ECBEn-1N9NkI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.apply(reset_weights)\n",
        "train(model, data, optimizer, criterion, epochs=50)\n",
        "\n",
        "# Evaluate the model\n",
        "acc = evaluate(model, data)\n",
        "print(f'Test accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHsLxmY6t7od",
        "outputId": "f71d31fd-7973-486c-a9a6-edf8c7c7d740"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 1.9878\n",
            "Epoch 11/50, Loss: 0.1874\n",
            "Epoch 21/50, Loss: 0.0036\n",
            "Epoch 31/50, Loss: 0.0001\n",
            "Epoch 41/50, Loss: 0.0000\n",
            "Test accuracy: 0.7470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import to_dense_adj\n",
        "# Node features (X)\n",
        "x = data.x  # Shape: [num_nodes, num_features]\n",
        "# Adjacency matrix (A)\n",
        "A = to_dense_adj(data.edge_index)[0]  # Shape: [num_nodes, num_nodes]\n",
        "K = (data.x) @ (data.x).T\n",
        "m = 1000"
      ],
      "metadata": {
        "id": "SR8XnfwMvDIg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Perturbe_Algs import Attacks\n",
        "from copy import deepcopy\n",
        "attack_instance = Attacks(A,K,m, alpha = 50, filter = 'adj', max_iter=250,).to(device)\n"
      ],
      "metadata": {
        "id": "cmhQkZtZdGIx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pgdavg_dataset = deepcopy(data)\n",
        "pgdwst_dataset = deepcopy(data)\n",
        "\n",
        "A_pgd_avg = attack_instance.Prob_PGD().clone().detach()\n",
        "A_pgd_wst = attack_instance.Wst_PGD().clone().detach()\n",
        "\n",
        "pgdavg_dataset.edge_index = torch.tensor(A_pgd_avg).nonzero(as_tuple=False).t().contiguous()\n",
        "pgdwst_dataset.edge_index = torch.tensor(A_pgd_wst).nonzero(as_tuple=False).t().contiguous()\n",
        "\n",
        "# Save the dataset object\n",
        "# Save the adjacency matrix (A)\n",
        "torch.save(A_pgd_avg, 'avg_adj.pt')\n",
        "torch.save(A_pgd_wst, 'wst_adj.pt')\n",
        "\n",
        "# Save the modified datasets\n",
        "torch.save(pgdavg_dataset, 'cora_pgdavg_data.pt')\n",
        "torch.save(pgdwst_dataset, 'cora_pgdwst_data.pt')\n",
        "\n",
        "print(\"Dataset and adjacency matrix saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6XGJa9h9uEm",
        "outputId": "edb96009-fd48-4b55-c59e-e831b5c0770b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Perturbe_Algs.py:248: UserWarning: torch.linalg.svd: During SVD computation with the selected cusolver driver, batches 0 failed to converge. A more accurate method will be used to compute the SVD as a fallback. Check doc at https://pytorch.org/docs/stable/generated/torch.linalg.svd.html (Triggered internally at /pytorch/aten/src/ATen/native/cuda/linalg/BatchLinearAlgebraLib.cpp:690.)\n",
            "  S_iter = S_iter + (a/torch.linalg.norm(S_iter.grad, ord=2)) * S_iter.grad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and adjacency matrix saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-97ca172e3aca>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  pgdavg_dataset.edge_index = torch.tensor(A_pgd_avg).nonzero(as_tuple=False).t().contiguous()\n",
            "<ipython-input-40-97ca172e3aca>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  pgdwst_dataset.edge_index = torch.tensor(A_pgd_wst).nonzero(as_tuple=False).t().contiguous()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the attacked graph adjacency matrix from file 'cora_adj'\n",
        "pgdavg_dataset = torch.load('cora_pgdavg_data.pt', weights_only=False)\n",
        "pgdwst_dataset = torch.load('cora_pgdwst_data.pt', weights_only=False)"
      ],
      "metadata": {
        "id": "m6RuaK64-C3x"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rep = 10\n",
        "\n",
        "list_ebd_random = []\n",
        "list_ebd_pgdavg = []\n",
        "list_ebd_pgdwst = []\n",
        "list_acc = []\n",
        "list_acc_random = []\n",
        "list_acc_pgdavg = []\n",
        "list_acc_pgdwst = []\n",
        "\n",
        "for i in range(num_rep):\n",
        "\n",
        "  A_random = attack_instance.randomAttack().clone().detach()\n",
        "  random_dataset = deepcopy(data)\n",
        "  random_dataset.edge_index = torch.tensor(A_random).nonzero(as_tuple=False).t().contiguous()\n",
        "\n",
        "  model.apply(reset_weights)\n",
        "  train(model, data, optimizer, criterion, epochs=50)\n",
        "  test_acc = evaluate(model, data)\n",
        "  acc_random = evaluate(model, random_dataset)\n",
        "  acc_pgdavg = evaluate(model, pgdavg_dataset)\n",
        "  acc_pgdwst = evaluate(model, pgdwst_dataset)\n",
        "\n",
        "  list_acc.append(test_acc)\n",
        "  list_acc_random.append(acc_random)\n",
        "  list_acc_pgdavg.append(acc_pgdavg)\n",
        "  list_acc_pgdwst.append(acc_pgdwst)\n",
        "\n",
        "\n",
        "  ebd = model.get_ebd(data.x, data.edge_index)\n",
        "  ebd_random = model.get_ebd(random_dataset.x, random_dataset.edge_index)\n",
        "  ebd_pgdavg = model.get_ebd(pgdavg_dataset.x, pgdavg_dataset.edge_index)\n",
        "  ebd_pgdwst = model.get_ebd(pgdwst_dataset.x, pgdwst_dataset.edge_index)\n",
        "\n",
        "\n",
        "  p_ebd_random = torch.norm(ebd - ebd_random, p='fro')\n",
        "  p_ebd_pgdavg = torch.norm(ebd - ebd_pgdavg, p='fro')\n",
        "  p_ebd_pgdwst = torch.norm(ebd - ebd_pgdwst, p='fro')\n",
        "\n",
        "  list_ebd_random.append(p_ebd_random.item())\n",
        "  list_ebd_pgdavg.append(p_ebd_pgdavg.item())\n",
        "  list_ebd_pgdwst.append(p_ebd_pgdwst.item())\n",
        "\n",
        "  print(f\"-----Iteration {i:d}-----\")\n",
        "  print(f\"Test Acc: {test_acc:.4f}\")\n",
        "  print(f\"PGD-AVG Test Acc: {acc_pgdavg:.4f}\")\n",
        "  print(f\"PGD-WST Test Acc: {acc_pgdwst:.4f}\")\n",
        "  print(f\"Random Test Acc: {acc_random:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQT7LlXi1Z9m",
        "outputId": "58045fb7-0094-4166-928b-36e4f6bd34d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-2f1362b35aee>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  random_dataset.edge_index = torch.tensor(A_random).nonzero(as_tuple=False).t().contiguous()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 2.0788\n",
            "Epoch 11/50, Loss: 0.0515\n",
            "Epoch 21/50, Loss: 0.0035\n",
            "Epoch 31/50, Loss: 1.1389\n",
            "Epoch 41/50, Loss: 0.0262\n",
            "-----Iteration 0-----\n",
            "Test Acc: 0.7500\n",
            "PGD-AVG Test Acc: 0.6030\n",
            "PGD-WST Test Acc: 0.7450\n",
            "Random Test Acc: 0.7130\n",
            "Epoch 1/50, Loss: 1.9864\n",
            "Epoch 11/50, Loss: 0.0850\n",
            "Epoch 21/50, Loss: 0.0027\n",
            "Epoch 31/50, Loss: 0.0005\n",
            "Epoch 41/50, Loss: 0.0002\n",
            "-----Iteration 1-----\n",
            "Test Acc: 0.7400\n",
            "PGD-AVG Test Acc: 0.5220\n",
            "PGD-WST Test Acc: 0.7320\n",
            "Random Test Acc: 0.6960\n",
            "Epoch 1/50, Loss: 2.1002\n",
            "Epoch 11/50, Loss: 0.5325\n",
            "Epoch 21/50, Loss: 0.0403\n",
            "Epoch 31/50, Loss: 0.0081\n",
            "Epoch 41/50, Loss: 0.0026\n",
            "-----Iteration 2-----\n",
            "Test Acc: 0.7370\n",
            "PGD-AVG Test Acc: 0.5850\n",
            "PGD-WST Test Acc: 0.7300\n",
            "Random Test Acc: 0.7090\n",
            "Epoch 1/50, Loss: 1.9784\n",
            "Epoch 11/50, Loss: 0.3130\n",
            "Epoch 21/50, Loss: 0.2085\n",
            "Epoch 31/50, Loss: 0.4564\n",
            "Epoch 41/50, Loss: 0.0042\n",
            "-----Iteration 3-----\n",
            "Test Acc: 0.7090\n",
            "PGD-AVG Test Acc: 0.4790\n",
            "PGD-WST Test Acc: 0.6910\n",
            "Random Test Acc: 0.6750\n",
            "Epoch 1/50, Loss: 1.9402\n",
            "Epoch 11/50, Loss: 0.7956\n",
            "Epoch 21/50, Loss: 0.0989\n",
            "Epoch 31/50, Loss: 0.0130\n",
            "Epoch 41/50, Loss: 0.0034\n",
            "-----Iteration 4-----\n",
            "Test Acc: 0.7570\n",
            "PGD-AVG Test Acc: 0.4960\n",
            "PGD-WST Test Acc: 0.7510\n",
            "Random Test Acc: 0.7070\n",
            "Epoch 1/50, Loss: 1.9883\n",
            "Epoch 11/50, Loss: 0.3666\n",
            "Epoch 21/50, Loss: 0.0812\n",
            "Epoch 31/50, Loss: 0.0068\n",
            "Epoch 41/50, Loss: 0.0019\n",
            "-----Iteration 5-----\n",
            "Test Acc: 0.7550\n",
            "PGD-AVG Test Acc: 0.5540\n",
            "PGD-WST Test Acc: 0.7480\n",
            "Random Test Acc: 0.7230\n",
            "Epoch 1/50, Loss: 1.9270\n",
            "Epoch 11/50, Loss: 0.0678\n",
            "Epoch 21/50, Loss: 0.0017\n",
            "Epoch 31/50, Loss: 0.0003\n",
            "Epoch 41/50, Loss: 0.0001\n",
            "-----Iteration 6-----\n",
            "Test Acc: 0.7640\n",
            "PGD-AVG Test Acc: 0.5700\n",
            "PGD-WST Test Acc: 0.7570\n",
            "Random Test Acc: 0.7280\n",
            "Epoch 1/50, Loss: 1.9208\n",
            "Epoch 11/50, Loss: 0.4625\n",
            "Epoch 21/50, Loss: 0.0619\n",
            "Epoch 31/50, Loss: 0.0064\n",
            "Epoch 41/50, Loss: 0.0029\n",
            "-----Iteration 7-----\n",
            "Test Acc: 0.7510\n",
            "PGD-AVG Test Acc: 0.5990\n",
            "PGD-WST Test Acc: 0.7410\n",
            "Random Test Acc: 0.7000\n",
            "Epoch 1/50, Loss: 2.0064\n",
            "Epoch 11/50, Loss: 0.1067\n",
            "Epoch 21/50, Loss: 0.0884\n",
            "Epoch 31/50, Loss: 0.0158\n",
            "Epoch 41/50, Loss: 0.0054\n",
            "-----Iteration 8-----\n",
            "Test Acc: 0.7480\n",
            "PGD-AVG Test Acc: 0.5420\n",
            "PGD-WST Test Acc: 0.7340\n",
            "Random Test Acc: 0.7260\n",
            "Epoch 1/50, Loss: 1.9999\n",
            "Epoch 11/50, Loss: 0.0891\n",
            "Epoch 21/50, Loss: 0.0055\n",
            "Epoch 31/50, Loss: 0.0010\n",
            "Epoch 41/50, Loss: 0.0005\n",
            "-----Iteration 9-----\n",
            "Test Acc: 0.7550\n",
            "PGD-AVG Test Acc: 0.5980\n",
            "PGD-WST Test Acc: 0.7480\n",
            "Random Test Acc: 0.7110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Test: {np.mean(list_acc)*100:.2f}, std:{np.std(list_acc)*100:.2f}\")\n",
        "print(f\"Mean of random: {np.mean(list_acc_random)*100:.2f}, std:{np.std(list_acc_random)*100:.2f}\")\n",
        "print(f\"Mean of Wst_PGD: {np.mean(list_acc_pgdwst)*100:.2f}, std: {np.std(list_acc_pgdwst)*100:.2f}\")\n",
        "print(f\"Mean of Prob_PGD:{np.mean(list_acc_pgdavg)*100:.2f}, std: {np.std(list_acc_pgdavg):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhjDXYM0cuQJ",
        "outputId": "44adc003-d344-48f0-e9b1-c686979e10db",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: 74.66, std:1.46\n",
            "Mean of random: 70.88, std:1.51\n",
            "Mean of Wst_PGD: 73.77, std: 1.76\n",
            "Mean of Prob_PGD:55.48, std: 0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean of random embedding norm: {np.mean(list_ebd_random):.2f}, std:{np.std(list_ebd_random):.2f}\")\n",
        "print(f\"Mean of Wst_PGD embedding norm: {np.mean(list_ebd_pgdwst):.2f}, std: {np.std(list_ebd_pgdwst):.2f}\")\n",
        "print(f\"Mean of Prob_PGD embedding norm:{np.mean(list_ebd_pgdavg):.2f}, std: {np.std(list_ebd_pgdavg):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBMLoi_C-Vvu",
        "outputId": "ba34fbe1-0bea-40e7-8639-7a8af124eabc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of random embedding norm: 1076.92, std:559.92\n",
            "Mean of Wst_PGD embedding norm: 17091.39, std: 13313.08\n",
            "Mean of Prob_PGD embedding norm:46628.58, std: 37193.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test: {np.mean(list_acc)*100:.2f} \\pm {np.std(list_acc)*100:.2f}\")\n",
        "print(f\"Mean of random: {np.mean(list_acc_random)*100:.2f} \\pm {np.std(list_acc_random)*100:.2f}\")\n",
        "print(f\"Mean of Wst_PGD: {np.mean(list_acc_pgdwst)*100:.2f} \\pm {np.std(list_acc_pgdwst)*100:.2f}\")\n",
        "print(f\"Mean of Prob_PGD:{np.mean(list_acc_pgdavg)*100:.2f} \\pm {np.std(list_acc_pgdavg):.2f}\")\n",
        "print(f\"Mean of random embedding norm: {np.mean(list_ebd_random):.2f} \\pm {np.std(list_ebd_random):.2f}\")\n",
        "print(f\"Mean of Wst_PGD embedding norm: {np.mean(list_ebd_pgdwst):.2f} \\pm {np.std(list_ebd_pgdwst):.2f}\")\n",
        "print(f\"Mean of Prob_PGD embedding norm:{np.mean(list_ebd_pgdavg):.2f} \\pm {np.std(list_ebd_pgdavg):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj_vOR1n-XYq",
        "outputId": "42931706-b84d-4be5-c41c-7a75bd737b05"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: 74.66 \\pm 1.46\n",
            "Mean of random: 70.88 \\pm 1.51\n",
            "Mean of Wst_PGD: 73.77 \\pm 1.76\n",
            "Mean of Prob_PGD:55.48 \\pm 0.04\n",
            "Mean of random embedding norm: 1076.92 \\pm 559.92\n",
            "Mean of Wst_PGD embedding norm: 17091.39 \\pm 13313.08\n",
            "Mean of Prob_PGD embedding norm:46628.58 \\pm 37193.34\n"
          ]
        }
      ]
    }
  ]
}